<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Detectors and Bias Towards Non-Native Students</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        /* Basic styling for the layout */
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            background-color: #f9f9f9;
            color: #333;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: #fff;
            padding: 20px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        h1 {
            font-size: 28px;
            color: #333;
            text-align: center;
        }
        h2 {
            font-size: 24px;
            color: #4CAF50;
            margin-top: 20px;
            border-bottom: 2px solid #4CAF50;
            padding-bottom: 5px;
        }
        p, li {
            font-size: 18px;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>

    <div class="container">
        <h1>AI Detectors Are Unfairly Penalizing Non-Native Students—Why Educators Should Care</h1>
        
        <p>Thanks for taking time to explore this important issue! As an educator, it’s important to recognize that AI bias can unfairly penalize your non-native English-speaking students. When their work is flagged as AI generated, they may face severe consequences, such as receiving a failing grade or being accused of academic dishonesty. This misclassification damages students’ academic reputation and undermines their confidence.</p>

        <p>Let’s dive into the core of this issue to see how it affects students and what can we do to mitigate the bias in educational aspect.</p>

        <!-- Section 1 -->
        <h2>1. What is AI Detection Bias Towards Non-native Speakers?</h2>

        <p>With the rapid development of generative Artificial Intelligence (AI) such as Chat-GPT and Claude, AI detectors are increasingly used in educational settings to ensure the academic integrity by differentiating students’ work from AI generated. AI detectors are designed to identify patterns in writing that classify whether the content was generated by AI. Typically, bias in the field of AI refers to the models which have a good performance in general, but they often make mistakes when they deal with a certain type of data. In this case, some of the AI detectors show promise by accurately identified texts created by native English speaker from the AI generated articles. However, these systems often fail to identify patterns typically used by non-native speakers, which eventually leads to the misclassifying. The existence of bias was proved by some scholars from Stanford University. In their study, seven widely used GPT detectors were tested on 91 essays written by Chinese students and 88 U.S. eighth-grade essays. As a result, 97.8% of essays written by Chinese students were incorrectly flagged as AI-generated by at least one detector.  <p>
        <!-- Paste the main content for Section 1 here -->
        <!-- COMMENT: Paste the main body content for "1. What is AI Detection Bias Towards Non-native Speakers?" -->

        <!-- Subsection 1.1 -->
        <h2>1.1 Why does this happen?</h2>
        <p>The main cause of this problem is the distinguished differences in sentence structures, vocabulary choices and grammatical patterns between non-native English speakers and native English speakers. Another experiment from Stanford further justified this point. Scholars first enhanced the vocabulary of TOEFL essays (standardized assessment for non-native speaker’s English ability) written by Chinese students to resemble native-speaker language. The results shown by the image below, the average misclassification rate dropped significantly from 61.3% to 11.6%. On the other hand, the misclassification rate as AI-generated text increased after simplifying the vocabulary of US eighth-grade essays to mimic non-native writing. This demonstrates that the bias is towards simpler language structures. Under this circumstance, non-native English speakers who tend to have a limited range of linguistic expressions and simpler sentence structures are more likely to be treats unfairly. (Want to know more about the mechnism behind the classification? click <a href="Proof.pdf">here</a>)<p>
        <!-- Paste the content for subsection 1.1 here -->
        <!-- COMMENT: Paste the main body content for "1.1 Why does this happen?" -->

        <figure>
            <img src="image_1.jpg" alt="Result analysis after modifying the word choices" style="width: 100%; max-width: 600px; margin-top: 20px;">
            <figcaption>Result analysis after modifying the word choices</figcaption>
        </figure>

        <!-- Section 2 -->
        <h2>2. How Does This Bias Affect Non-native Speaking Students</h2>
        <p>The bias in AI detection tools has profound and lasting impact beyond only misclassification, especially in educational and cultural contexts. Non-native English speakers need to mimic the writing style of standardized English to avoid the penalty brought by misclassification, since this writing style is less likely to trigger the detection. However, the negative consequences rise from the process when non-native English-speaking students alter their writing styles.<p>
        <!-- Paste the main content for Section 2 here -->
        <!-- COMMENT: Paste the main body content for "2. How Does This Bias Affect Non-native Speaking Students" -->

        <!-- Subsection 2.1 -->
        <h2>2.1 Educational Implication</h2>
        <p>Non-native English speakers make efforts to change their writing styles by using complex sentence structures or employing more complicated vocabulary, as these adjustments are less likely to trigger detection. While these adjustments reduce the chance of misclassification, only focusing on modifying their language to align with the expectations of AI detection tools, such practice takes away from the meaning of studying. The research from Western Norway University of Applied Sciences suggests that students who concentrate on avoiding detection were struggled to cultivate their broader academic writing abilities. To be more specific, non-native speaking students may focus more on using "safe" language patterns that are unlikely to raise suspicion to avoid detection. As a result, this behavior diverts their attention from developing more critical academic skills, such as argumentation and critical thinking. In a word, using biased AI detectors can ultimately hinder non-native speaking students’ overall learning experience, as they prioritize meeting AI detection expectations over improving their academic proficiency.  <p>
        <!-- Paste the content for subsection 2.1 here -->
        <!-- COMMENT: Paste the main body content for "2.1 Educational Implication" -->

        <!-- Subsection 2.2 -->
        <h2>2.2 Cultural Implication</h2>
        <p>In addition to the impact on learning experience, this shift in writing style can also diminish cultural richness in academic discourse. As non-native students adjust to writing in standardized English to avoid their creations being flagged as AI generated incorrectly, their unique cultural expressions, idioms and linguistic features will be faded gradually. Over time, there will be less diversity and creativity of language used in academic and professional environments, because students are restricted to express themselves creatively and culturally by the pressure to conform to AI’s expectations.<p>
       
        <p>Ultimately, while adapting writing to meet AI standards may help non-native students avoid bias, it comes to the sacrifice of their linguistic authenticity, creativity and further academic development. This highlights the need for educators to recognize these biases in evaluating students’ work. <p>
        <!-- Paste the content for subsection 2.2 here -->
        <!-- COMMENT: Paste the main body content for "2.2 Cultural Implication" -->

        <!-- Section 3 -->
        <h2>3. Practical Suggestions</h2>
        <p>Now that you are aware of the bias in AI detectors, here are a few suggestions to better ensure fair treatment for non-native English-speaking students:<p>
        <!-- Paste the main content for Section 3 here -->
        <!-- COMMENT: Paste the main body content for "3. Practical Suggestions" -->

        <!-- Subsection 3.1 -->
        <h2>3.1 Manually Check the AI’s Prediction</h2>
        <p>After recognizing the existence of bias in AI detection tools, educators can foster open communication by creating a supportive environment where students feel safe discussing concerns about AI detection biases. A considerable step is to emphasize that mistakes or false flags are part of the learning process. By doing so, educators can help students understand that their value as learners goes beyond the limitations of AI tools. This approach can ease student anxiety and empower them to take ownership of their work, which allow students to know they are supported. By empowering students with knowledge and support, educators can help them confidently navigate these challenges, reducing anxiety and building resilience. As a result, educators can encourage students, especially non-native English speakers who disproportionally been affected to face this challenge, rather than escape.<p>
        <!-- Paste the content for subsection 3.1 here -->
        <!-- COMMENT: Paste the main body content for "3.1 Manually Check the AI’s Prediction" -->

        <!-- Subsection 3.2 -->
        <h2>3.2 Use Turnitin’s AI Detector as a Benchmark</h2>
        <p>Although opening communication can create an environment to support the students, other methods were needed to correct the misclassification directly.<p>
        <p>Actively participating in AI decision-making rather than relying solely on AI outputs has a huge potential for mitigating the AI bias. Educators ought to review AI detection during deployment, especially for flagged outputs marked as AI-generated or plagiarism. More specifically, if an AI system classifies certain text as AI-generated, the educator needs to review that text again to see if this is a correct detection or a misclassification. If this is a misclassification caused by non-native English speakers’ linguistic differences that detectors failed to identify, educators can correct this unjust flag. As educators have contextual understanding that AI lacks, they can consider students backgrounds, intentions and writing styles, so that they are able to give fair judgement on students’ work. To further enhance this process, educators can corporately review this enquired article with other colleagues, and if necessary, submit it to leader of the faculty for double-checking. Therefore, the results are more authorized and credible, as they are the final decision of all staff. As a result, this method ensures the fairness and comprehensiveness towards all students’ work.<p>
        <p>The advantages of Turnitin’s AI detector are far beyond. Turnitin only presents the highlights if the overall percentage of AI-generated content in a paper exceeds 20%. If the AI-generated content is below this threshold, no score or highlights are shown to users, since Turnitin treats every score below this threshold to a false-positive value. The threshold of 20% ensures that small instances of flagged text do not lead to unnecessary penalties, which might disproportionately affect NNS whose writing styles differ from those of NS. In a word, Turnitin’s AI detectors allows for more nuanced review, while minimizing unnecessary impact for smaller AI-generated sections.<p>
        <!-- Paste the content for subsection 3.2 here -->
        <!-- COMMENT: Paste the main body content for "3.2 Use Turnitin’s AI Detector as a Benchmark" -->

        <!-- Subsection 3.3 -->
        <h2>3.3 Opening Communications</h2>
        <p>Some educators may worry about manually checking the whole article will cost too much time, using AI detector in Turnitin can solve this problem.<p>
        
        <p>The AI detector in Turnitin is a system that uses one of the most advanced algorithms to analyze writing patterns and identify contents that may be generated by AI. That is to say, using Turnitin’s AI detector as a benchmark is beneficial, because it offers a standardized and continually updated tool that helps educators ensure academic integrity, while minimizing biases in detecting AI-generated contents. What’s more, instead of classifying the texts as AI-generated or human-written like other detectors, detection reports from Turnitin highlights the specific sentences or paragraphs which are likely to be AI-generated. Under this circumstance, human reviewers can merely focus on checking these highlighted parts rather than reviewing whole articles. Therefore, the reviewing efficiency of educators will be significantly improved.<p>
        <p>The advantages of this AI detector are far beyond. Turnitin only presents the highlights if the overall percentage of AI-generated content in a paper exceeds 20%. If the AI-generated content is below this threshold, no score or highlights are shown to users, since Turnitin treats every score below this threshold as misclassification. The threshold of 20% ensures that small instances of flagged text do not lead to unnecessary penalties. In a word, Turnitin’s AI detectors allows for more nuanced review, while minimizing unnecessary impact for smaller AI-generated sections (Want to hear more about the possible solutions? Click <a href="Solutions.pdf">here</a>).<p>
        <!-- Paste the content for subsection 3.3 here -->
        <!-- COMMENT: Paste the main body content for "3.3 Opening Communications" -->

        <!-- Section 4 -->
        <h2>4. Conclusion</h2>
        <p>As AI detection tools become increasingly integrated into academic settings, it is crucial for educators to be aware of the potential biases in these systems, especially towards non-native English-speaking students. These biases not only affect students' academic performance, but also hinder their abilities to express their authentic voices and undermine both their academic growth and cultural contributions.<p>

        <p>By understanding the challenges that AI tools present, more inclusive and fairer practices can be introduced, such as manually reviewing flagged work, using reliable systems like the AI detecting function in Turnitin as a benchmark, and fostering open communication with students about these issues. By doing so, educators can help to create a more supportive and equitable learning environment, ensuring that non-native students are not unfairly penalized and are empowered to thrive academically. In a word, recognizing the limitations of AI detection tools will help educators uphold the values of academic integrity while fostering a richer, more inclusive academic discourse.<p>
        <!-- Paste the main content for Section 4 here -->
        <!-- COMMENT: Paste the main body content for "4. Conclusion" -->
    </div>

</body>
</html>


