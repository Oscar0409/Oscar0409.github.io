<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Detectors and Bias Towards Non-Native Students</title>
    <link rel="stylesheet" href="styles.css">
    <style>
        /* Basic styling for the layout */
        body {
            font-family: Arial, sans-serif;
            line-height: 1.6;
            background-color: #f9f9f9;
            color: #333;
            margin: 0;
            padding: 20px;
        }
        .container {
            max-width: 800px;
            margin: 0 auto;
            background-color: #fff;
            padding: 20px;
            box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1);
        }
        h1 {
            font-size: 28px;
            color: #333;
            text-align: center;
        }
        h2 {
            font-size: 24px;
            color: #4CAF50;
            margin-top: 20px;
            border-bottom: 2px solid #4CAF50;
            padding-bottom: 5px;
        }
        p, li {
            font-size: 18px;
            margin-bottom: 10px;
        }
    </style>
</head>
<body>

    <div class="container">
        <h1>AI Detectors Are Unfairly Penalizing Non-Native Students—Here’s Why Educators Should Care</h1>
        
        <p>Thanks for taking the time to explore this important issue! As an educator, it’s important to recognize that AI bias can unfairly penalize your non-native English-speaking students. When their work is flagged by these tools, they may face severe consequences, such as receiving a failing grade or being accused of academic dishonesty. This misclassification can damage students’ academic reputation and undermine their confidence.</p>

        <p>Let’s dive into the core of this issue to see how it affects both students and educators and what can we do to mitigate the bias from educational aspect.</p>

        <!-- Section 1 -->
        <h2>1. What is AI Detection Bias Towards Non-native Speakers?</h2>

        <p>With the rapid development of generative Artificial Intelligence (AI) such as Chat-GPT and claude, AI detectors are increasingly used in educational settings to ensure the academic integrity by differentiating students’ work from AI genreated. 
            AI detectors are designed to identify patterns in writing that classify whether the content was generated by another AI. Typically, bias in the field of AI refers to the models have a good performance in general but it often make mistake when 
            facing a certain type of data. In this case, some of the AI detectors show promise by accurately idenfitied tests created by native English speaker from the AI generated articles. However, these systems often failed to identify patterns typically used by non-native speakers, which eventually leads to the misclassifing non-native English speakers' work as AI-generated. The existence of bias was proved by some scholars from Stanford University. In their study, seven widely used GPT detectors were tested on 91 essays written by Chinese students and 88 U.S. eighth-grade essays. As a result, 97.8% of essays writen by Chinese students were incorrectly flagged as AI-generated by at least one detector. <p>
        <!-- Paste the main content for Section 1 here -->
        <!-- COMMENT: Paste the main body content for "1. What is AI Detection Bias Towards Non-native Speakers?" -->

        <!-- Subsection 1.1 -->
        <h2>1.1 Why does this happen?</h2>
        <p>The main cause of this problem is non-native speakers often have different sentence structures, vocabulary choices, and grammatical patterns. Another experiment from Stanford further justified this opinion. Result as the image below shos, after scholars enhanced the vocabulary of essays writen by Chinese students from TOEFL essays (a standardized assessment for non-native speaker’s English ability) to resemble native-speaker language, average misclassification rate droped significantly from 61.3% to 11.6%. On the other hand, the misclassification rate as AI-generated text increased after simplifying the vocabulary of US eighth-grade essays to mimic non-native writing. This demonstrates that the bias toward simpler language structures. Under this circumstance, non-native speakers, who tend to have a limited range of linguistic expressions and simpler sentence structures are more likely to be treats unfairly. (Want to know more about the mechnism behind the classification? click <a href="Proof.pdf">here</a>)<p>
        <!-- Paste the content for subsection 1.1 here -->
        <!-- COMMENT: Paste the main body content for "1.1 Why does this happen?" -->

        <figure>
            <img src="image_1.jpg" alt="Result analysis after modifying the word choices" style="width: 100%; max-width: 600px; margin-top: 20px;">
            <figcaption>Result analysis after modifying the word choices</figcaption>
        </figure>

        <!-- Section 2 -->
        <h2>2. How Does This Bias Affect Non-native Speaking Students</h2>
        <p>The bias in AI detection tools has far-reaching consequences beyond mere misclassification, especially in educational and cultural contexts. Since students will receive severe consequences for using AI generated contents without pointing it out, they have to make sure their own work not been flagged as AI generated. However, the negative consequences rise from the process when non-native English speaking students alter their writing styles to avoid AI misdetection.<p>
        <!-- Paste the main content for Section 2 here -->
        <!-- COMMENT: Paste the main body content for "2. How Does This Bias Affect Non-native Speaking Students" -->

        <!-- Subsection 2.1 -->
        <h2>2.1 Educational Implication</h2>
        <p>In their efforts to change their writing styles, non-native speaking students use complex sentence structures or employ more complicated vocabulary, as these adjustments are less likely to trigger detection tools. While these adjustments reduce the chance of misclassification, focusing on modify their language to align with the expectations of AI detection tools takes away from the meaning of practicing. Study from Western Norway University of Applied Sciences suggests that students who concentrate on avoiding detection were struggled to cultivate their broader academic writing abilities. To be more specific, non-native speaking students may focus more on using "safe" language patterns that are unlikely to raise suspicion to avoid detection. This is because this behavior actually diverts their attention from developing more critical academic skills, such as argumentation and critical thinking. In a word, using biased AI detectors can ultimately hinders non-native speaking students’ overall learning experience, as they prioritize meeting AI detection expectations over improving their academic proficiency. <p>
        <!-- Paste the content for subsection 2.1 here -->
        <!-- COMMENT: Paste the main body content for "2.1 Educational Implication" -->

        <!-- Subsection 2.2 -->
        <h2>2.2 Cultural Implication</h2>
        <p>In addition to the impact on learning experience, this shift in writing style can also diminish the cultural richness in academic discourse. As non-native students adjust to writing in standardized English to avoid being flagged, their cultural expressions, idioms, and unique linguistic features gradually fade. Over time, there will be less diversity and creativity of language used in academic and professional environments. Instead of contributing their distinctive perspectives, students may find their ability to express themselves creatively and culturally constrained by the pressure to conform to AI’s expectations.<p>
       
        <p>Ultimately, while adapting writing to meet AI standards may help non-native students avoid bias, it comes at the cost of their linguistic authenticity, creativity, and broader academic development. This highlights the need for educators to recognize these biases and reconsider how AI detection tools are used in educational assessments.<p>
        <!-- Paste the content for subsection 2.2 here -->
        <!-- COMMENT: Paste the main body content for "2.2 Cultural Implication" -->

        <!-- Section 3 -->
        <h2>3. Practical Suggestions</h2>
        <p>Now that you’re aware of the bias in AI detectors, here are a few suggestions to help ensure fair treatment for non-native English-speaking students:<p>
        <!-- Paste the main content for Section 3 here -->
        <!-- COMMENT: Paste the main body content for "3. Practical Suggestions" -->

        <!-- Subsection 3.1 -->
        <h2>3.1 Manually Check the AI’s Prediction</h2>
        <p>Actively participate in AI decision-making rather than relying solely on AI outputs has a huge potential for mitigating the bias in AI detectors towards non-native speakers. Educators will review AI predictions during deployment, especially for flagged outputs like AI-generated work or plagiarism. More specifically, if an AI system classifies the texts created by non-native speaking students as AI-generated due to linguistic differences, the educator needs to review the text and may correct unjust flags. In this pattern, educators also provide contextual understanding that AI lacks, considering individual student backgrounds, intent and writing styles. <p>
        <!-- Paste the content for subsection 3.1 here -->
        <!-- COMMENT: Paste the main body content for "3.1 Manually Check the AI’s Prediction" -->

        <!-- Subsection 3.2 -->
        <h2>3.2 Use Turnitin’s AI Detector as a Benchmark</h2>
        <p>Some educators may worry about manually check every article will spend too much time, using Turnitin’s AI detector can solve this concern.<p>
        <p>Turnitin’s AI detector, a system that uses one of the most advanced algorithms to analyze writing patterns and identify content that may be generated by artificial intelligence. That is to say, using Turnitin’s AI detector as benchmark is beneficial because it offers a standardized, continually updated tool that helps educators ensure academic integrity while minimizing biases in detecting AI-generated content. What’s more, instead of classifying the texts as AI-generated or human-written like other detectors, the reports from Turnitin contains highlight for specific sentences or paragraphs in the writings that are likely to be AI-generated. Under this circumstance, human reviewers can merely focus on checking these highlighted parts rather than reviewing whole articles. Therefore, staffs’ reviewing efficiency will be significantly improved.<p>
        <p>The advantages of Turnitin’s AI detector are far beyond. Turnitin only presents the highlights if the overall percentage of AI-generated content in a paper exceeds 20%. If the AI-generated content is below this threshold, no score or highlights are shown to users, since Turnitin treats every score below this threshold to a false-positive value. The threshold of 20% ensures that small instances of flagged text do not lead to unnecessary penalties, which might disproportionately affect NNS whose writing styles differ from those of NS. In a word, Turnitin’s AI detectors allows for more nuanced review, while minimizing unnecessary impact for smaller AI-generated sections.<p>
        <!-- Paste the content for subsection 3.2 here -->
        <!-- COMMENT: Paste the main body content for "3.2 Use Turnitin’s AI Detector as a Benchmark" -->

        <!-- Subsection 3.3 -->
        <h2>3.3 Opening Communications</h2>
        <p>Given that one of the most advanced AI detection systems may also make misclassification, it’s essential for both educators and students to approach these tools with an understanding of their limitations and a commitment to fair evaluation practices.<p>
        
        <p>Informing students about the potential biases in AI detection tools can help them better understand the unique challenges, especially for non-native English speakers. More specifically, emphasizing that these tools might flag their writing as AI generation and encouraging them to explain their situation. By doing so, they know that their educators are open to discussing these issues, and that being flagged does not automatically mean their work will be penalized. This approach can ease student anxiety and empower them to take ownership of their work, knowing they are supported. Additionally, by making students aware of the limitations of AI detection, educators can help them feel more confident in expressing their unique linguistic style, allowing for a more inclusive and fair educational experience (Want to hear more about the possible solutions? Click <a href="Solutions.pdf">here</a>).<p>
        <!-- Paste the content for subsection 3.3 here -->
        <!-- COMMENT: Paste the main body content for "3.3 Opening Communications" -->

        <!-- Section 4 -->
        <h2>4. Conclusion</h2>
        <p>As AI detection tools become increasingly integrated into academic settings, it’s crucial for educators to be aware of the potential biases these systems may introduce, especially toward non-native English-speaking students. These biases not only affect students' academic performance but also hinder their ability to express their authentic voices, undermining both their academic growth and cultural contributions.<p>

        <p>By understanding the challenges that AI tools present, more inclusive and fair practices can be presented, such as manually reviewing flagged work, using reliable systems like Turnitin’s AI detector as a benchmark, and fostering open communication with students about these issues. By doing so, educators can help create a more supportive and equitable learning environment, ensuring that non-native students are not unfairly penalized and are empowered to thrive academically. In a word, recognizing the limitations of AI detection tools will help educators uphold the values of academic integrity while fostering a richer, more inclusive academic discourse.<p>
        <!-- Paste the main content for Section 4 here -->
        <!-- COMMENT: Paste the main body content for "4. Conclusion" -->
    </div>

</body>
</html>


